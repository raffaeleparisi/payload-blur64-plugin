{"version":3,"file":"index.js","mappings":";;AAAA;AACA;AACA;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACNA;AACA;;;;;;;;;;;;;ACDA;;ACAA;;ACAA;;;ACAA;;ACAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAIA;;;;;AAIA;AAEA;AACA;AACA;AACA;AACA;;AAJA;AAMA;;;AAOA;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/RA;AACA;AACA;AAEA;AAIA;;;;;AAIA;AAEA;;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAJA;AAMA;AAIA;;;AACA;;;AClCA;AACA;AAWA;AACA;AACA;AACA;AAmBA;AAIA;AACA;AAAA;AAcA;AAKA;AACA;AACA;AAEA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChEA;AACA;AACA;AAgBA;AACA;AAOA;AAEA;;AACA;AAAA;;;;;;;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAAA;AAEA;;;;AAIA;AAEA;;AAIA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AAEA;AAKA;;AAIA;AAcA;AAGA;AAGA;AACA;AAEA","sources":["../webpack/bootstrap","../webpack/runtime/compat get default export","../webpack/runtime/define property getters","../webpack/runtime/hasOwnProperty shorthand","../webpack/runtime/make namespace object","../webpack/runtime/compat","../external node-commonjs \"path\"","../external node-commonjs \"minimatch\"","../external node-commonjs \"sharp\"","../external node-commonjs \"blurhash\"","../external node-commonjs \"zod\"",".././src/algorithms/blurhash.ts",".././node_modules/thumbhash/thumbhash.js",".././src/algorithms/thumbhash.ts",".././src/algorithms/index.ts",".././src/index.ts"],"sourcesContent":["// The require scope\nvar __webpack_require__ = {};\n\n","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = (module) => {\n\tvar getter = module && module.__esModule ?\n\t\t() => (module['default']) :\n\t\t() => (module);\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = __dirname + \"/\";","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"path\");","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"minimatch\");","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"sharp\");","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"blurhash\");","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"zod\");","import sharp from 'sharp';\nimport { encode } from 'blurhash';\nimport { z } from 'zod';\n\nexport const BlurhashOptionsSchema = z.object({\n  width: z.number().optional(),\n  height: z.number().optional(),\n  componentX: z.number().optional(),\n  componentY: z.number().optional(),\n});\n\nexport type BlurhashOptions = z.infer<typeof BlurhashOptionsSchema>;\n\nexport const imageToBlurhash = async (\n  data: Buffer,\n  options: BlurhashOptions,\n) => {\n  const { width = 32, height = 32, componentX = 3, componentY = 3 } = options;\n\n  const rawPixels = await sharp(data)\n    .resize(width, height)\n    .ensureAlpha(1)\n    .raw()\n    .toBuffer();\n\n  return encode(\n    new Uint8ClampedArray(rawPixels),\n    width,\n    height,\n    componentX,\n    componentY,\n  );\n};\n","/**\n * Encodes an RGBA image to a ThumbHash. RGB should not be premultiplied by A.\n *\n * @param w The width of the input image. Must be ≤100px.\n * @param h The height of the input image. Must be ≤100px.\n * @param rgba The pixels in the input image, row-by-row. Must have w*h*4 elements.\n * @returns The ThumbHash as a Uint8Array.\n */\nexport function rgbaToThumbHash(w, h, rgba) {\n  // Encoding an image larger than 100x100 is slow with no benefit\n  if (w > 100 || h > 100) throw new Error(`${w}x${h} doesn't fit in 100x100`)\n  let { PI, round, max, cos, abs } = Math\n\n  // Determine the average color\n  let avg_r = 0, avg_g = 0, avg_b = 0, avg_a = 0\n  for (let i = 0, j = 0; i < w * h; i++, j += 4) {\n    let alpha = rgba[j + 3] / 255\n    avg_r += alpha / 255 * rgba[j]\n    avg_g += alpha / 255 * rgba[j + 1]\n    avg_b += alpha / 255 * rgba[j + 2]\n    avg_a += alpha\n  }\n  if (avg_a) {\n    avg_r /= avg_a\n    avg_g /= avg_a\n    avg_b /= avg_a\n  }\n\n  let hasAlpha = avg_a < w * h\n  let l_limit = hasAlpha ? 5 : 7 // Use fewer luminance bits if there's alpha\n  let lx = max(1, round(l_limit * w / max(w, h)))\n  let ly = max(1, round(l_limit * h / max(w, h)))\n  let l = [] // luminance\n  let p = [] // yellow - blue\n  let q = [] // red - green\n  let a = [] // alpha\n\n  // Convert the image from RGBA to LPQA (composite atop the average color)\n  for (let i = 0, j = 0; i < w * h; i++, j += 4) {\n    let alpha = rgba[j + 3] / 255\n    let r = avg_r * (1 - alpha) + alpha / 255 * rgba[j]\n    let g = avg_g * (1 - alpha) + alpha / 255 * rgba[j + 1]\n    let b = avg_b * (1 - alpha) + alpha / 255 * rgba[j + 2]\n    l[i] = (r + g + b) / 3\n    p[i] = (r + g) / 2 - b\n    q[i] = r - g\n    a[i] = alpha\n  }\n\n  // Encode using the DCT into DC (constant) and normalized AC (varying) terms\n  let encodeChannel = (channel, nx, ny) => {\n    let dc = 0, ac = [], scale = 0, fx = []\n    for (let cy = 0; cy < ny; cy++) {\n      for (let cx = 0; cx * ny < nx * (ny - cy); cx++) {\n        let f = 0\n        for (let x = 0; x < w; x++)\n          fx[x] = cos(PI / w * cx * (x + 0.5))\n        for (let y = 0; y < h; y++)\n          for (let x = 0, fy = cos(PI / h * cy * (y + 0.5)); x < w; x++)\n            f += channel[x + y * w] * fx[x] * fy\n        f /= w * h\n        if (cx || cy) {\n          ac.push(f)\n          scale = max(scale, abs(f))\n        } else {\n          dc = f\n        }\n      }\n    }\n    if (scale)\n      for (let i = 0; i < ac.length; i++)\n        ac[i] = 0.5 + 0.5 / scale * ac[i]\n    return [dc, ac, scale]\n  }\n  let [l_dc, l_ac, l_scale] = encodeChannel(l, max(3, lx), max(3, ly))\n  let [p_dc, p_ac, p_scale] = encodeChannel(p, 3, 3)\n  let [q_dc, q_ac, q_scale] = encodeChannel(q, 3, 3)\n  let [a_dc, a_ac, a_scale] = hasAlpha ? encodeChannel(a, 5, 5) : []\n\n  // Write the constants\n  let isLandscape = w > h\n  let header24 = round(63 * l_dc) | (round(31.5 + 31.5 * p_dc) << 6) | (round(31.5 + 31.5 * q_dc) << 12) | (round(31 * l_scale) << 18) | (hasAlpha << 23)\n  let header16 = (isLandscape ? ly : lx) | (round(63 * p_scale) << 3) | (round(63 * q_scale) << 9) | (isLandscape << 15)\n  let hash = [header24 & 255, (header24 >> 8) & 255, header24 >> 16, header16 & 255, header16 >> 8]\n  let ac_start = hasAlpha ? 6 : 5\n  let ac_index = 0\n  if (hasAlpha) hash.push(round(15 * a_dc) | (round(15 * a_scale) << 4))\n\n  // Write the varying factors\n  for (let ac of hasAlpha ? [l_ac, p_ac, q_ac, a_ac] : [l_ac, p_ac, q_ac])\n    for (let f of ac)\n      hash[ac_start + (ac_index >> 1)] |= round(15 * f) << ((ac_index++ & 1) << 2)\n  return new Uint8Array(hash)\n}\n\n/**\n * Decodes a ThumbHash to an RGBA image. RGB is not be premultiplied by A.\n *\n * @param hash The bytes of the ThumbHash.\n * @returns The width, height, and pixels of the rendered placeholder image.\n */\nexport function thumbHashToRGBA(hash) {\n  let { PI, min, max, cos, round } = Math\n\n  // Read the constants\n  let header24 = hash[0] | (hash[1] << 8) | (hash[2] << 16)\n  let header16 = hash[3] | (hash[4] << 8)\n  let l_dc = (header24 & 63) / 63\n  let p_dc = ((header24 >> 6) & 63) / 31.5 - 1\n  let q_dc = ((header24 >> 12) & 63) / 31.5 - 1\n  let l_scale = ((header24 >> 18) & 31) / 31\n  let hasAlpha = header24 >> 23\n  let p_scale = ((header16 >> 3) & 63) / 63\n  let q_scale = ((header16 >> 9) & 63) / 63\n  let isLandscape = header16 >> 15\n  let lx = max(3, isLandscape ? hasAlpha ? 5 : 7 : header16 & 7)\n  let ly = max(3, isLandscape ? header16 & 7 : hasAlpha ? 5 : 7)\n  let a_dc = hasAlpha ? (hash[5] & 15) / 15 : 1\n  let a_scale = (hash[5] >> 4) / 15\n\n  // Read the varying factors (boost saturation by 1.25x to compensate for quantization)\n  let ac_start = hasAlpha ? 6 : 5\n  let ac_index = 0\n  let decodeChannel = (nx, ny, scale) => {\n    let ac = []\n    for (let cy = 0; cy < ny; cy++)\n      for (let cx = cy ? 0 : 1; cx * ny < nx * (ny - cy); cx++)\n        ac.push((((hash[ac_start + (ac_index >> 1)] >> ((ac_index++ & 1) << 2)) & 15) / 7.5 - 1) * scale)\n    return ac\n  }\n  let l_ac = decodeChannel(lx, ly, l_scale)\n  let p_ac = decodeChannel(3, 3, p_scale * 1.25)\n  let q_ac = decodeChannel(3, 3, q_scale * 1.25)\n  let a_ac = hasAlpha && decodeChannel(5, 5, a_scale)\n\n  // Decode using the DCT into RGB\n  let ratio = thumbHashToApproximateAspectRatio(hash)\n  let w = round(ratio > 1 ? 32 : 32 * ratio)\n  let h = round(ratio > 1 ? 32 / ratio : 32)\n  let rgba = new Uint8Array(w * h * 4), fx = [], fy = []\n  for (let y = 0, i = 0; y < h; y++) {\n    for (let x = 0; x < w; x++, i += 4) {\n      let l = l_dc, p = p_dc, q = q_dc, a = a_dc\n\n      // Precompute the coefficients\n      for (let cx = 0, n = max(lx, hasAlpha ? 5 : 3); cx < n; cx++)\n        fx[cx] = cos(PI / w * (x + 0.5) * cx)\n      for (let cy = 0, n = max(ly, hasAlpha ? 5 : 3); cy < n; cy++)\n        fy[cy] = cos(PI / h * (y + 0.5) * cy)\n\n      // Decode L\n      for (let cy = 0, j = 0; cy < ly; cy++)\n        for (let cx = cy ? 0 : 1, fy2 = fy[cy] * 2; cx * ly < lx * (ly - cy); cx++, j++)\n          l += l_ac[j] * fx[cx] * fy2\n\n      // Decode P and Q\n      for (let cy = 0, j = 0; cy < 3; cy++) {\n        for (let cx = cy ? 0 : 1, fy2 = fy[cy] * 2; cx < 3 - cy; cx++, j++) {\n          let f = fx[cx] * fy2\n          p += p_ac[j] * f\n          q += q_ac[j] * f\n        }\n      }\n\n      // Decode A\n      if (hasAlpha)\n        for (let cy = 0, j = 0; cy < 5; cy++)\n          for (let cx = cy ? 0 : 1, fy2 = fy[cy] * 2; cx < 5 - cy; cx++, j++)\n            a += a_ac[j] * fx[cx] * fy2\n\n      // Convert to RGB\n      let b = l - 2 / 3 * p\n      let r = (3 * l - b + q) / 2\n      let g = r - q\n      rgba[i] = max(0, 255 * min(1, r))\n      rgba[i + 1] = max(0, 255 * min(1, g))\n      rgba[i + 2] = max(0, 255 * min(1, b))\n      rgba[i + 3] = max(0, 255 * min(1, a))\n    }\n  }\n  return { w, h, rgba }\n}\n\n/**\n * Extracts the average color from a ThumbHash. RGB is not be premultiplied by A.\n *\n * @param hash The bytes of the ThumbHash.\n * @returns The RGBA values for the average color. Each value ranges from 0 to 1.\n */\nexport function thumbHashToAverageRGBA(hash) {\n  let { min, max } = Math\n  let header = hash[0] | (hash[1] << 8) | (hash[2] << 16)\n  let l = (header & 63) / 63\n  let p = ((header >> 6) & 63) / 31.5 - 1\n  let q = ((header >> 12) & 63) / 31.5 - 1\n  let hasAlpha = header >> 23\n  let a = hasAlpha ? (hash[5] & 15) / 15 : 1\n  let b = l - 2 / 3 * p\n  let r = (3 * l - b + q) / 2\n  let g = r - q\n  return {\n    r: max(0, min(1, r)),\n    g: max(0, min(1, g)),\n    b: max(0, min(1, b)),\n    a\n  }\n}\n\n/**\n * Extracts the approximate aspect ratio of the original image.\n *\n * @param hash The bytes of the ThumbHash.\n * @returns The approximate aspect ratio (i.e. width / height).\n */\nexport function thumbHashToApproximateAspectRatio(hash) {\n  let header = hash[3]\n  let hasAlpha = hash[2] & 0x80\n  let isLandscape = hash[4] & 0x80\n  let lx = isLandscape ? hasAlpha ? 5 : 7 : header & 7\n  let ly = isLandscape ? header & 7 : hasAlpha ? 5 : 7\n  return lx / ly\n}\n\n/**\n * Encodes an RGBA image to a PNG data URL. RGB should not be premultiplied by\n * A. This is optimized for speed and simplicity and does not optimize for size\n * at all. This doesn't do any compression (all values are stored uncompressed).\n *\n * @param w The width of the input image. Must be ≤100px.\n * @param h The height of the input image. Must be ≤100px.\n * @param rgba The pixels in the input image, row-by-row. Must have w*h*4 elements.\n * @returns A data URL containing a PNG for the input image.\n */\nexport function rgbaToDataURL(w, h, rgba) {\n  let row = w * 4 + 1\n  let idat = 6 + h * (5 + row)\n  let bytes = [\n    137, 80, 78, 71, 13, 10, 26, 10, 0, 0, 0, 13, 73, 72, 68, 82, 0, 0,\n    w >> 8, w & 255, 0, 0, h >> 8, h & 255, 8, 6, 0, 0, 0, 0, 0, 0, 0,\n    idat >>> 24, (idat >> 16) & 255, (idat >> 8) & 255, idat & 255,\n    73, 68, 65, 84, 120, 1\n  ]\n  let table = [\n    0, 498536548, 997073096, 651767980, 1994146192, 1802195444, 1303535960,\n    1342533948, -306674912, -267414716, -690576408, -882789492, -1687895376,\n    -2032938284, -1609899400, -1111625188\n  ]\n  let a = 1, b = 0\n  for (let y = 0, i = 0, end = row - 1; y < h; y++, end += row - 1) {\n    bytes.push(y + 1 < h ? 0 : 1, row & 255, row >> 8, ~row & 255, (row >> 8) ^ 255, 0)\n    for (b = (b + a) % 65521; i < end; i++) {\n      let u = rgba[i] & 255\n      bytes.push(u)\n      a = (a + u) % 65521\n      b = (b + a) % 65521\n    }\n  }\n  bytes.push(\n    b >> 8, b & 255, a >> 8, a & 255, 0, 0, 0, 0,\n    0, 0, 0, 0, 73, 69, 78, 68, 174, 66, 96, 130\n  )\n  for (let [start, end] of [[12, 29], [37, 41 + idat]]) {\n    let c = ~0\n    for (let i = start; i < end; i++) {\n      c ^= bytes[i]\n      c = (c >>> 4) ^ table[c & 15]\n      c = (c >>> 4) ^ table[c & 15]\n    }\n    c = ~c\n    bytes[end++] = c >>> 24\n    bytes[end++] = (c >> 16) & 255\n    bytes[end++] = (c >> 8) & 255\n    bytes[end++] = c & 255\n  }\n  return 'data:image/png;base64,' + btoa(String.fromCharCode(...bytes))\n}\n\n/**\n * Decodes a ThumbHash to a PNG data URL. This is a convenience function that\n * just calls \"thumbHashToRGBA\" followed by \"rgbaToDataURL\".\n *\n * @param hash The bytes of the ThumbHash.\n * @returns A data URL containing a PNG for the rendered ThumbHash.\n */\nexport function thumbHashToDataURL(hash) {\n  let image = thumbHashToRGBA(hash)\n  return rgbaToDataURL(image.w, image.h, image.rgba)\n}\n","import { z } from 'zod';\nimport sharp from 'sharp';\nimport { rgbaToThumbHash } from 'thumbhash';\n\nexport const ThumbhashOptionsSchema = z.object({});\n\nexport type ThumbhashOptions = z.infer<typeof ThumbhashOptionsSchema>;\n\nexport const imageToThumbhash = async (\n  data: Buffer,\n  _options: ThumbhashOptions,\n) => {\n  const image = sharp(data);\n\n  const metadata = await image.metadata();\n  if (metadata.width == null || metadata.height == null) {\n    throw new Error('Encountered an image without a width/height');\n  }\n\n  const scale = 100 / Math.max(metadata.width, metadata.height);\n  const newWidth = Math.round(metadata.width * scale);\n  const newHeight = Math.round(metadata.height * scale);\n\n  const rawPixels = await image\n    .resize(newWidth, newHeight)\n    .ensureAlpha(1)\n    .raw()\n    .toBuffer();\n\n  const thumbhash = Buffer.from(\n    rgbaToThumbHash(newWidth, newHeight, rawPixels),\n  );\n\n  return thumbhash.toString('base64');\n};\n","import { imageToBlurhash, BlurhashOptionsSchema } from './blurhash';\nimport { imageToThumbhash, ThumbhashOptionsSchema } from './thumbhash';\nimport { z } from 'zod';\nimport { Equal, ExpectTrue } from '../types';\n\nexport type Algorithm = (\n  data: Buffer,\n  options: Record<string, unknown>,\n) => Promise<string>;\n\ntype ExtractAlgorithmOptions<T extends Algorithm> = Parameters<T>[1];\n\nexport const algorithms = {\n  blurhash: [imageToBlurhash, BlurhashOptionsSchema] as const,\n  thumbhash: [imageToThumbhash, ThumbhashOptionsSchema] as const,\n};\n\ntype Algorithms = typeof algorithms;\n\ntype AlgorithmValidity = {\n  [Key in keyof Algorithms]: Algorithms[Key] extends readonly [\n    infer Algo extends Algorithm,\n    infer Schema extends z.AnyZodObject,\n  ]\n    ? Equal<ExtractAlgorithmOptions<Algo>, z.infer<Schema>>\n    : false;\n};\n\ntype EnsureAlgorithmValidity = ExpectTrue<\n  AlgorithmValidity[keyof AlgorithmValidity]\n>;\n\ntype AlgorithmType = keyof Algorithms;\n\nexport const defaultAlgorithm = 'blurhash' satisfies AlgorithmType;\n\ntype DefaultAlgorithm = typeof defaultAlgorithm;\n\nconst isAlgorithmType = (type: string): type is AlgorithmType =>\n  type in algorithms;\n\nexport type AlgorithmOptions = {\n  [Key in keyof Algorithms]: Algorithms[Key] extends readonly [\n    infer Algo extends Algorithm,\n    ...unknown[],\n  ]\n    ? (Key extends DefaultAlgorithm\n        ? { algorithm?: Key }\n        : { algorithm: Key }) &\n        ExtractAlgorithmOptions<Algo>\n    : never;\n}[keyof Algorithms];\n\nexport const runAlgorithm = (\n  algorithmType: string,\n  data: Buffer,\n  options: Record<string, unknown>,\n) => {\n  if (!isAlgorithmType(algorithmType)) {\n    throw new Error(`Unknown algorithm: ${algorithmType}`);\n  }\n\n  const [algorithm, schema] = algorithms[algorithmType];\n  const parsedOptions = schema.parse(options);\n\n  return algorithm(data, parsedOptions);\n};\n","import { Config } from 'payload/config';\nimport { CollectionConfig, CollectionBeforeChangeHook } from 'payload/types';\nimport * as path from 'path';\nimport { Minimatch } from 'minimatch';\nimport { AlgorithmOptions, defaultAlgorithm, runAlgorithm } from './algorithms';\n\nexport type BlurhashPluginOptions = {\n  /*\n   * Array of collection slugs that the plugin should apply to.\n   * By default, the plugin will apply to all collections with `upload` properties.\n   */\n  collections?: CollectionConfig['slug'][];\n\n  /*\n   * Pattern to determine which MIME types to target\n   * Default: image/*\n   */\n  mimeTypePattern?: string;\n} & AlgorithmOptions;\n\nconst computeBlurhash = (pluginOptions?: BlurhashPluginOptions) => {\n  const {\n    collections,\n    mimeTypePattern = 'image/*',\n    algorithm = defaultAlgorithm,\n    ...options\n  } = pluginOptions ?? {};\n\n  const mimeTypeMatcher = new Minimatch(mimeTypePattern);\n\n  return (incomingConfig: Config): Config => {\n    const hook: CollectionBeforeChangeHook = async ({ data, req }) => {\n      if (!req.collection) {\n        return data;\n      }\n\n      if (!mimeTypeMatcher.match(data.mimeType)) {\n        return data;\n      }\n\n      const file = req.files?.file;\n      if (file == null || !('data' in file)) {\n        return data;\n      }\n\n      const fileData = file.data;\n      if (!Buffer.isBuffer(fileData)) {\n        return data;\n      }\n\n      const blurhash = await runAlgorithm(algorithm, fileData, options);\n\n      return {\n        ...data,\n        blurhash,\n      };\n    };\n\n    return {\n      ...incomingConfig,\n      collections:\n        incomingConfig.collections?.map((collection) => {\n          if (!collection.upload) {\n            return collection;\n          }\n\n          if (collections && !collections.includes(collection.slug)) {\n            return collection;\n          }\n\n          return {\n            ...collection,\n            fields: [\n              ...collection.fields,\n              {\n                name: 'blurhash',\n                type: 'text',\n              },\n            ],\n            hooks: {\n              ...collection.hooks,\n              beforeChange: [...(collection.hooks?.beforeChange ?? []), hook],\n            },\n          };\n        }) ?? [],\n      admin: {\n        ...incomingConfig.admin,\n        webpack: (webpackConfig) => {\n          const modifiedConfig = {\n            ...webpackConfig,\n            resolve: {\n              ...webpackConfig.resolve,\n              alias: {\n                ...webpackConfig.resolve?.alias,\n                '@raffaeleparisi/payload-blurhash-plugin': path.resolve(\n                  __dirname,\n                  './mock-plugin',\n                ),\n              },\n            },\n          };\n\n          return (\n            incomingConfig.admin?.webpack?.(modifiedConfig) ?? modifiedConfig\n          );\n        },\n      },\n    };\n  };\n};\n\nexport default computeBlurhash;\n"],"names":[],"sourceRoot":""}